library(phyloseq) # for handling phyloseq objects
library(Hmisc) # library for the rcorr function
library(igraph) # for preparing and plotting networks
#### load and prepare the data ----

# set the topX parameters for bacteria and total fungi
# prevtopX <- 0.05 # prevalence portions
perctopX <- 1 # minimum relative abundance percentage for the prevtopX portion of samples

# loop the analysis for varying combinations of prevalence (can do it for percentages as well but the 1% relative abundance seems a good compromise) 

for(prevtopX in c(0.05, 0.1)){
  ### GTDs fungi
  PathogenASVsFull <- readRDS("PathogenASVsFull.RDS") # read the dataset
  PathogenASVsFull_net_gen <- tax_glom(PathogenASVsFull, taxrank = "Genus") # agglomerate taxa at genus level
  taxa_names(PathogenASVsFull_net_gen) <- gsub("^[a-z]__","",tax_table(PathogenASVsFull_net_gen)[,"Genus"]) # set the genera to taxon names
  Fungi_GTD <- transform_sample_counts(PathogenASVsFull_net_gen, function(OTU) 100*OTU/sum(OTU)) # convert to percentages (not representative for the dataset but does not affect the Spearman correlations used as input material for the network analysis)
  Fungi_GTD <- prune_samples(!(sample_names(Fungi_GTD) %in% (c("X41"))), Fungi_GTD) # remove X41 which is an outlier
  
  
  ### top X bacteria
  BACTERIAFINALWOOD1Plot <- readRDS("BACTERIAFINALWOOD.RDS") # read the dataset
  BacteriaWood_net_gen <- tax_glom(BACTERIAFINALWOOD1Plot, taxrank = "Genus") # agglomerate taxa at genus level
  BacteriaWood_net_gen100 <- transform_sample_counts(BacteriaWood_net_gen, function(OTU) 100*OTU/sum(OTU)) # convert to percentages
  BacteriaWood_net_gen100 <- prune_taxa(taxa_sums(BacteriaWood_net_gen100)>0,BacteriaWood_net_gen100) # remove possible empty taxa
  networkBacteria <- BacteriaWood_net_gen100 # refresh nomenclature
  taxa_names(networkBacteria) <- gsub("^[a-z]__","",tax_table(networkBacteria)[,"Genus"]) # set the genera to taxon names
  topBacteria_names <- colnames(otu_table(networkBacteria)[,apply(otu_table(networkBacteria), 2, function(x) {if(length(which(x > perctopX)) > prevtopX * length(sample_names(networkBacteria))) { TRUE } else { FALSE }})]) # identify the X most abundant genera
  topBacteria <- prune_taxa(topBacteria_names, networkBacteria) # select the X most abundant genera
  sample_data(topBacteria)$state <- gsub("Healthy.+","Healthy",gsub("Diseased.+","Diseased",sample_data(topBacteria)$state)) # correct an issue with the state variable
  
  ### top X fungi
  FUNGIFINALWOOD1Plot <- readRDS("FUNGIFINALWOOD.RDS") # read the dataset
  FUNGIFINALWOOD1Plot_glom <- tax_glom(FUNGIFINALWOOD1Plot, taxrank = "Genus") # agglomerate taxa at genus level
  taxa_names(FUNGIFINALWOOD1Plot_glom) <- gsub("^[a-z]__","",tax_table(FUNGIFINALWOOD1Plot_glom)[,"Genus"]) # set the genera to taxon names
  FUNGIFINALWOOD1Plot_glom100 <- transform_sample_counts(FUNGIFINALWOOD1Plot_glom, function(OTU) 100*OTU/sum(OTU)) # convert to percentages
  topFungi_names <- colnames(otu_table(FUNGIFINALWOOD1Plot_glom100)[,apply(otu_table(FUNGIFINALWOOD1Plot_glom100), 2, function(x) {if(length(which(x > perctopX)) > prevtopX * length(sample_names(FUNGIFINALWOOD1Plot_glom100))) { TRUE } else { FALSE }})]) # identify the X most abundant genera
  ps.topFungi <- prune_taxa(topFungi_names, FUNGIFINALWOOD1Plot_glom100) # select the X most abundant genera
  ps.topFungi <- prune_samples(!(sample_names(ps.topFungi) %in% (c("X41"))), ps.topFungi) # remove X41 which seems to be an outlier
  topFungi <- prune_taxa(taxa_sums(ps.topFungi)>0,ps.topFungi) # double-check for possible empty taxa after the sample removal
  sample_data(topFungi)$state <- gsub("Healthy.+","Healthy",gsub("Diseased.+","Diseased",sample_data(topFungi)$state)) # correct an issue with the state variable
  
  
  ### GTDs combined with top X bacteria
  GTDs_topBac <- merge_phyloseq(Fungi_GTD, topBacteria) # merge the phyloseq objects (it is important to have the taxa named not named with (representative) ASV codes in order to avoid merging possibly common ASV code counts/percentages)
  GTDs_topBac <- prune_samples(!sample_names(GTDs_topBac) %in% (c("X41")), GTDs_topBac) # remove the outlier X41 sample series
  GTDs_topBac <- prune_taxa(taxa_sums(GTDs_topBac)>0,GTDs_topBac) # remove possible empty taxa generated by the outlier removal
  
  
  ### top X fungi combined with top X bacteria
  topFungi_topBac <- merge_phyloseq(topFungi, topBacteria) # merge the phyloseq objects (it is important to have the taxa named not named with (representative) ASV codes in order to avoid merging possibly common ASV code counts/percentages)
  topFungi_topBac <- prune_samples(!(sample_names(topFungi_topBac) %in% (c("X41"))), topFungi_topBac) # remove the outlier X41 sample series
  topFungi_topBac <- prune_taxa(taxa_sums(topFungi_topBac)>0,topFungi_topBac) # remove possible empty taxa generated by the outlier removal
  
  
  
  
  
  
  #### Analyze and plot the data ----
  ### Several nice tips for preparing the network plot at: https://www.biostars.org/p/285296/
  
  myvarchoices <- c("all","Vidiano","Xinomavro","Agiorgitiko")
  mydatasets <- c("Fungi_GTD","topBacteria","topFungi","GTDs_topBac","topFungi_topBac")
  mystates <- c("all","Diseased","Healthy")
  mypvaladjs <- c("none","BH")
  myrcutoffs <- c(0,0.5)
  mypvalcutoffs <- c(0.05, 0.01)
  
  
  for(myvarchoice in myvarchoices){
    # create the directory to save the files based on the variety
    system(paste("mkdir -p prevalence_",prevtopX,"/",myvarchoice, sep = ""))
    
    for(mypvaladj in mypvaladjs){
      for(myrcutoff in myrcutoffs){
        for(mypvalcutoff in mypvalcutoffs){
          
          # start a graphics device there
          cairo_pdf(paste("prevalence_",prevtopX,"/",myvarchoice,"/corPadj_",mypvaladj,"_rCutoff_",myrcutoff,"_PValCutoff_",mypvalcutoff,".pdf", sep = ""), height = 12, width = 12, onefile = T)
          
          for(mydataset in mydatasets){
            for(mystate in mystates){
              
              if(myvarchoice == "all"){
                mypsobj_pre <- get(mydataset)
              } else {
                mypsobj_pre <- get(mydataset)
                sample_data(mypsobj_pre)$variety <- factor(sample_data(mypsobj_pre)$variety) # set to factor... for some reason it hangs at Xinomavro
                mypsobj_pre <- subset_samples(mypsobj_pre,variety == myvarchoice) # subset according to the variety
                mypsobj_pre <- prune_taxa(taxa_sums(mypsobj_pre) > 0, mypsobj_pre) # remove orphan taxa after the sample removal
              }
              
              # select ps object samples according to status and set the labels
              if(mystate == "all"){
                mypsobj <- mypsobj_pre
                mystatelabel <- "sympt. & asympt."
              } else {
                mypsobj <- subset_samples(mypsobj_pre,state == mystate)
                mypsobj <- prune_taxa(taxa_sums(mypsobj) > 0,mypsobj)
                if(mystate == "Diseased"){
                  mystatelabel <- "symptomatic"
                } else if(mystate == "Healthy"){
                  mystatelabel <- "asymptomatic"
                }
              }
              
              # make a final check to test if the number of samples left is above the minimum required for the correlations
              myNsamp <- length(sample_sums(mypsobj))
              if(myNsamp < 5){
                next
              }
              
              # obtain the Spearman correlation values
              correl <- rcorr(as.matrix(otu_table(mypsobj)), type = "spearman")
              
              # save the r and p values in objects for downstream manipulation according to the set cutoffs
              r_vals<-correl$r
              p_vals<-correl$P
              # set the diagonal of the p_values object to one (to avoid self loops.... although this I remove also with the simplify command)
              diag(p_vals)<-1
              
              # adjust the p-values for multiple hypothesis testing
              p_vals_arr <- array(p_vals) # convert to an array
              p_vals_arr_adj <- p.adjust(p_vals_arr, method = mypvaladj) # adjust the p-values according to the selected method
              p_vals_arr_adj_mat <- matrix(p_vals_arr_adj, nrow = nrow(p_vals), ncol = ncol(p_vals)) # convert back to a matrix
              colnames(p_vals_arr_adj_mat) <- row.names(p_vals_arr_adj_mat) <- row.names(p_vals) # set the row and column names
              
              # set the r_vals according to decided adjusted p-value and r/rho cutoffs
              r_vals_padj <- r_vals # assign the new r_values
              r_vals_padj_mat <- ifelse(p_vals_arr_adj_mat > mypvalcutoff,0,r_vals_padj) # adjust by setting to zero non-significant values
              
              # in case where all r values are set to zero you need to abort the current network testing/plotting and proceed with the next test
              if(all(r_vals_padj_mat == 0)){
                next
              }
              
              # if all went well run the graph algorithm
              ## Several nice tips for preparing the network plot at: https://www.biostars.org/p/285296/
              g<-graph.adjacency(r_vals_padj_mat
                                 , weighted=TRUE # for the edge calculation using continuous values
                                 , diag=FALSE # we have also set the r_values to zero further up... so not necessary, but better safe than sorry
                                 , mode="undirected" # undirected is the mode of choice
              )
              
              # modify plotting parameters
              E(g)[which(E(g)$weight<0)]$color <- "darkred" # Colour negative correlation edges as red
              E(g)[which(E(g)$weight>0)]$color <- "darkgreen" # Colour positive correlation edges as green
              E(g)$weight <- abs(E(g)$weight) # Convert edge weights to absolute values
              V(g)$shape <- "sphere" # Change shape of graph vertices
              V(g)$color <- "skyblue" # Change colour of graph vertices
              V(g)$vertex.frame.color <- "white" # Change colour of vertex frames
              vSizes <- colMeans(data.frame(otu_table(mypsobj)), na.rm = T) # Calculate the size of the vertices to be proportional to the relative abundance of each taxon represented by each vertex
              edgeweights <- E(g)$weight * 16 # Amplify or decrease the width of the edges
              
              # Convert the graph adjacency object into a minimum spanning tree based on Prim's algorithm
              mst <- mst(g, algorithm="prim")
              
              # Identify sub-communities
              mst.communities <- edge.betweenness.community(mst, weights=NULL, directed=FALSE) # calculate the betweenness centrality for edges in order to use for the cluster calculations 
              mst.clustering <- make_clusters(mst, membership=mst.communities$membership) # calculate the memberships
              myvertcols <- tax_table(mypsobj)[,1]
              myvertcols[which(tax_table(mypsobj)[,1] == "k__Fungi")] <- "skyblue"
              myvertcols[which(tax_table(mypsobj)[,1] == "Bacteria")] <- "lightgreen"
              V(mst)$color <- myvertcols
              
              # do a last sanity check
              if(length(V(mst)$color) == 0){
                next
              }
              
              
              # prepare the plot
              plot(
                mst
                , mark.groups=communities(mst.clustering)
                , layout=layout.fruchterman.reingold
                , edge.curved=TRUE
                , vertex.size=vSizes,
                , vertex.label.dist=ifelse(vSizes/5 > 2, 2, vSizes/4)
                , vertex.label.color="black"
                , asp=FALSE
                , vertex.label.cex=1.1
                , edge.width=edgeweights
                , edge.arrow.mode=0
                , main=paste(mydataset," ",mystatelabel," // corPadj ",mypvaladj,", rCutoff ",myrcutoff,", PValCutoff ",mypvalcutoff,", n samp. ",myNsamp, sep = "")
              )
              
            }
          }
          
          # close the graphics device
          dev.off()
          
        }
      }
    }
  }
  
}

